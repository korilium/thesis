
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>3. Financial Application of Reinforcement Learning &#8212; Future Financial Planning Tools for Consumers</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/layout.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="2. Reinforcement Learning" href="Reinforcement_learning.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      <img src="_static/pipe.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Future Financial Planning Tools for Consumers</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="abstract.html">
   Abstract
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction.html">
   1. Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Reinforcement_learning.html">
   2. Reinforcement Learning
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   3. Financial Application of Reinforcement Learning
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/Financial_application.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/Financial_application.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimal-consumption-investment-and-life-insurance-in-an-intertemporal-model">
   3.1. Optimal consumption, investment and life insurance in an intertemporal model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-model-specifications">
     3.1.1. The model specifications
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dynamic-programming-principle">
     3.1.2. dynamic programming principle
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-analytic-result-constant-relative-risk-aversion-utility-function">
     3.1.3. The analytic result: Constant Relative Risk Aversion utility function
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#algorithm-bfsde">
   3.2. Algorithm BFSDE
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="financial-application-of-reinforcement-learning">
<h1><span class="section-number">3. </span>Financial Application of Reinforcement Learning<a class="headerlink" href="#financial-application-of-reinforcement-learning" title="Permalink to this headline">¶</a></h1>
<div class="section" id="optimal-consumption-investment-and-life-insurance-in-an-intertemporal-model">
<h2><span class="section-number">3.1. </span>Optimal consumption, investment and life insurance in an intertemporal model<a class="headerlink" href="#optimal-consumption-investment-and-life-insurance-in-an-intertemporal-model" title="Permalink to this headline">¶</a></h2>
<p>The first person to include uncertain lifetime and life insurance decisions in a discrete life-cycle model was Yaari <span id="id1">[<a class="reference internal" href="#id19">Yaa65</a>]</span>. He explored the model using a utility function without bequest (Fisher Utility function) and a utility function with bequest (Marshall Utility function) in a bounded lifetime. In both cases, he looked at the implications of including life insurance. Although Yaari’s model was revolutionary in the sense that now the uncertainty of life could be modeled, Leung <span id="id2">[<a class="reference internal" href="#id23">Leu94</a>]</span> found that the constraints laid upon the Fisher utility function were not adequate and lead to terminal wealth depletion. Richard <span id="id3">[<a class="reference internal" href="#id22">Ric75</a>]</span> applied the methodology of Merton <span id="id4">[<a class="reference internal" href="#id20">Mer69</a>, <a class="reference internal" href="#id21">Mer75</a>]</span> to the problem setting of Yaari in a continuous time frame. Unfortunately, Richard’s model had one deficiency: The bounded lifetime is incompatible with the dynamic programming approach used in Merton’s model. As an individual approaches his maximal possible lifetime T, he will be inclined to buy an infinite amount of life insurance. To circumvent this Richard used an artificial condition on the terminal value. But due to the recursive nature of dynamic programming, modifying the last value would imply modifying the whole result. Ye <span id="id5">[<a class="reference internal" href="#id24">Ye06</a>]</span>  found a solution to the problem by abandoning the bounded random lifetime and replacing it with a random variable taking values in <span class="math notranslate nohighlight">\([0,\infty)\)</span>. The models that replaced the bounded lifetime, are thereafter called intertemporal models as the models did not consider the whole lifetime of an individual but rather looked at the planning horizon of the consumer.  Note that the general setting of Ye <span id="id6">[<a class="reference internal" href="#id24">Ye06</a>]</span> has a wide range of theoretical variables, while still upholding a flexible approach to different financial settings. On this account, it is a good baseline to confront the issues concerning the current models of financial planning. However, one of the downsides of the model is the abstract representation of the consumer. Namely, the rational consumer is studied, instead of the actual consumer. To detach the model from the notion of rational consumer, I will more closely look at behavioral concepts that can be implemented. In the next paragraph various modification will be discussed and a further review is conducted on the behavioral modifications</p>
<p>After Ye <span id="id7">[<a class="reference internal" href="#id24">Ye06</a>]</span> various models have been proposed which all have given rise to unique solutions to the consumption, investment, and insurance problem. The first unique setting is a model with multiple agents involved. For example,  Bruhn and Steffensen <span id="id8">[<a class="reference internal" href="#id30">BS11</a>]</span> analyzed the optimization problem for couples with correlated lifetimes with their partner nominated as their beneficiary using a copula and common-shock model, while Wei et al.<span id="id9">[<a class="reference internal" href="#id33">WCJW20</a>]</span> studied optimization strategies for a household with economically and probabilistically dependent persons. Another setting is where certain constraints are used to better describe the financial situation of consumers. Namely, Kronborg and Steffensen <span id="id10">[<a class="reference internal" href="#id32">KS15</a>]</span> discussed two constraints. One constraint is a capital constraint on the savings in which savings cannot drop below zero. The other constrain involves a minimum return in savings. A third setting describes models who analyze the financial market and insurance market in a pragmatic environment. A good illustration is the study of Shen and Wei <span id="id11">[<a class="reference internal" href="#id34">SW16</a>]</span>. They incorporate all stochastic processes involved in the investment and insurance market where all randomness is described by a Brownian motion filtration. An interesting body of models is involved in time-inconsistent preferences. In this framework, consumers do not have a time-consistent rate of preference as assumed in the economic literature. There exists rather a divergence between earlier intentions and later choices De-Paz et al. <span id="id12">[<a class="reference internal" href="#id37">DPMSNR14</a>]</span>. This concept is predominantly described in psychology. Specifically, rewards presented closer to the present are discounted proportionally less than rewards further into the future. An application of time-inconsistent preferences in the consumption, investment, and insurance optimization can be found in Chen and Li <span id="id13">[<a class="reference internal" href="#id36">CL20</a>]</span> and De-Paz et al. <span id="id14">[<a class="reference internal" href="#id37">DPMSNR14</a>]</span>. These time-inconsistent preferences are rooted in a much deeper behavioral concept called future self-continuity. Future self-continuity can be described as how someone sees himself in the future. In classical economic theory, we assume that the degree to which you identify with yourself has no impact on the ultimate result. In the next subsection, the relationship of future self-continuity and time-inconsistent preferences are more closely looked at and future self-continuity is further examined in the behavioral life-cycle model.</p>
<div class="section" id="the-model-specifications">
<h3><span class="section-number">3.1.1. </span>The model specifications<a class="headerlink" href="#the-model-specifications" title="Permalink to this headline">¶</a></h3>
<p>In this section, I will set the dynamics for the baseline model in place. The dynamics follow primarily from the paper of Ye <span id="id15">[<a class="reference internal" href="#id24">Ye06</a>]</span>.</p>
<p>Let the state of the economy be represented by a standard Brownian motion <span class="math notranslate nohighlight">\(w(t)\)</span>, the state of the consumer’s wealth be characterized by a finite state multi-dimensional continuous-time Markov chain <span class="math notranslate nohighlight">\(X(t)\)</span> and let the time of death be defined by a non-negative random variable <span class="math notranslate nohighlight">\(\tau\)</span>. All are defined on a given probability space (<span class="math notranslate nohighlight">\(\Omega, \mathcal{F}, P\)</span>) and <span class="math notranslate nohighlight">\(W(t)\)</span> is independent of <span class="math notranslate nohighlight">\(\tau\)</span>. Let <span class="math notranslate nohighlight">\(T&lt; \infty\)</span> be a fixed planning horizon. This can be seen as the end of the working life for the consumer. <span class="math notranslate nohighlight">\(\mathbb{F} = \{\mathcal{F}_t, t \in [0,T]\}\)</span>, be the P-augmentation of the filtration <span class="math notranslate nohighlight">\(\sigma\)</span>{<span class="math notranslate nohighlight">\(W(s), s&lt;t \}, \forall t \in [0,T]\)</span> , so <span class="math notranslate nohighlight">\(\mathcal{F}_t\)</span> represents the information at time t. The economy consist of a financial market and an insurance market. In the following section I will construct these markets separetly.</p>
<p>The financial market consist of a risk-free security <span class="math notranslate nohighlight">\(B(t)\)</span> and a risky security <span class="math notranslate nohighlight">\(S(t)\)</span>, who evolve according to</p>
<div class="math notranslate nohighlight">
\[ \frac{dB(t)}{B(t)}=r(t)dt \]</div>
<div class="math notranslate nohighlight">
\[ \frac{dS(t)}{S(t)}=\mu(t)dt+\sigma(t)dW(t)\]</div>
<p>Where <span class="math notranslate nohighlight">\(\mu, \sigma, r &gt; 0\)</span> are constants and <span class="math notranslate nohighlight">\(\mu(t), r(t), \sigma(t): [0,T] \to R\)</span> are continous. With <span class="math notranslate nohighlight">\(\sigma(t)\)</span> satisfying <span class="math notranslate nohighlight">\(\sigma^2(t) \ge k, \forall t \in [0,T]\)</span></p>
<p>The random variable <span class="math notranslate nohighlight">\(\tau_d\)</span> needs to be first modeled for the insurance  market. Assume that <span class="math notranslate nohighlight">\(\tau\)</span> has a probability density function <span class="math notranslate nohighlight">\(f(t)\)</span> and probability distribution function given by</p>
<div class="math notranslate nohighlight">
\[ F(t) \triangleq P(\tau &lt; t) = \int_0^t f(u) du \]</div>
<p>Assuming <span class="math notranslate nohighlight">\(\tau\)</span> is independent of the filtration <span class="math notranslate nohighlight">\(\mathbb{F}\)</span></p>
<p>Following on the probability distribution function we can define the survival function as followed</p>
<div class="math notranslate nohighlight">
\[ \bar{F}(t)\triangleq P(\tau \ge t) = 1 -F(t) \]</div>
<p>The hazard function is the  instantaneous death rate for the consumer at time t and is defined by</p>
<div class="math notranslate nohighlight">
\[ \lambda(t) = \lim_{\Delta t\to 0} = \frac{P(t\le\tau &lt; t+\Delta t| \tau \ge t)}{\Delta t} \]</div>
<p>where <span class="math notranslate nohighlight">\(\lambda(t): [0,\infty[ \to R^+\)</span> is a continuous, deterministic function with <span class="math notranslate nohighlight">\(\int_0^\infty \lambda(t) dt = \infty\)</span>.</p>
<p>Subsequently, the survival and probability density function can be characterized by</p>
<div class="math notranslate nohighlight">
\[ \bar{F}(t)= {}_tp_0= e^{-\int_0^t \lambda(u)du} \]</div>
<div class="math notranslate nohighlight">
\[ f(t)=\lambda(t) e^{-\int_0^t\lambda(u)du} \]</div>
<p>With conditional probability described as</p>
<div class="math notranslate nohighlight">
\[ f(s,t) \triangleq \frac{f(s)}{\bar{F}(t)}=\lambda(s) e^{-\int_t^s\lambda(u)dy} \]</div>
<div class="math notranslate nohighlight">
\[ \bar{F}(s,t) = {}_sp_t \triangleq \frac{\bar{F}(s)}{\bar{F}(t)} = e^{-\int_t^s \lambda(u)du} \]</div>
<p>Now that <span class="math notranslate nohighlight">\(\tau\)</span> has been modeled, the life insurance market can be constructed. Let’s assume that the life insurance is continuously offered and that it provides coverage for an infinitesimally small period of time. In return, the consumer pays a premium rate p when he enters into a life insurance contract, so that he might insure his future income. In compensation he will receive  a total benefit of <span class="math notranslate nohighlight">\(\frac{p}{\eta(t)}\)</span> when he dies at time t. Where <span class="math notranslate nohighlight">\(\eta : [0,T] \to R^+ \)</span> is a continuous, deterministic function.</p>
<p>Both markets are now described and the wealth process <span class="math notranslate nohighlight">\(X(t)\)</span> of the consumer can now be constructed. Given an initial wealth <span class="math notranslate nohighlight">\(x_0\)</span>, the consumer receives a certain amount of income <span class="math notranslate nohighlight">\(i(t)\)</span> <span class="math notranslate nohighlight">\(\forall t \in [0,\tau \wedge T]\)</span> and satisfying <span class="math notranslate nohighlight">\(\int_0^{\tau \wedge T} i(u)du &lt; \infty\)</span>. He needs to choose at time t a certain premium rate <span class="math notranslate nohighlight">\(p(t)\)</span>, a certain consumption rate <span class="math notranslate nohighlight">\(c(t)\)</span> and a certain amount of his wealth <span class="math notranslate nohighlight">\(\theta (t)\)</span> that he invest into the risky asset <span class="math notranslate nohighlight">\(S(t)\)</span>. So given the processes <span class="math notranslate nohighlight">\(\theta\)</span>, c, p and i, there is a wealth process <span class="math notranslate nohighlight">\(X(t)\)</span>  <span class="math notranslate nohighlight">\(\forall t \in [0, \tau \wedge T] \)</span> determined by</p>
<div class="math notranslate nohighlight">
\[ dX(t) = r(t)X(t) + \theta(t)[( \mu(t) - r(t))dt +\sigma(t)dW(t)] -c(t)dt -p(t)dt + i(t)dt,   \quad t \in [0,\tau \wedge T] \]</div>
<p>If <span class="math notranslate nohighlight">\(t=\tau\)</span> then the consumer will receive the insured amount <span class="math notranslate nohighlight">\(\frac{p(t)}{\eta(t)}\)</span>. Given is wealth X(t) at time t his total legacy will be</p>
<div class="math notranslate nohighlight">
\[ Z(t) = X(t) + \frac{p(t)}{\eta(t)} \]</div>
<p>The predicament for the consumer is that he needs to chose the optimal rates for c, p , <span class="math notranslate nohighlight">\(\theta\)</span> from the set <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> , called the set of admissible strategies, defined by</p>
<div class="math notranslate nohighlight">
\[ \mathcal{A}(x) \triangleq  \textrm{set of all possible triplets (c,p,}\theta) \]</div>
<p>such that his expected utility from consumption, from legacy when <span class="math notranslate nohighlight">\(\tau &gt; T\)</span> and from terminal wealth when <span class="math notranslate nohighlight">\(\tau \leq T \)</span>  is maximized.</p>
<div class="math notranslate nohighlight">
\[ V(x) \triangleq \sup_{(c,p,\theta) \in \mathcal{A}(x)} E\left[\int_0^{T \wedge \tau} U(c(s),s)ds + B(Z(\tau),\tau)1_{\{\tau \ge T\}} + L(X(T))1_{\{\tau&gt;T\}}\right] \]</div>
<p>Where <span class="math notranslate nohighlight">\(U(c,t)\)</span> is the utility function of consumption, <span class="math notranslate nohighlight">\(B(Z,t)\)</span> is the utility function of legacy and <span class="math notranslate nohighlight">\(L(X)\)</span> is the utility function for the terminal wealth. <span class="math notranslate nohighlight">\(V(x)\)</span> is called the value function and the consumers wants to maximize his value function by choosing the optimal set <span class="math notranslate nohighlight">\(\mathcal{A} = (c,p,\theta)\)</span>. The optimal set <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> is found by using the dynamic programming technique described in the following section.</p>
</div>
<div class="section" id="dynamic-programming-principle">
<h3><span class="section-number">3.1.2. </span>dynamic programming principle<a class="headerlink" href="#dynamic-programming-principle" title="Permalink to this headline">¶</a></h3>
<p>To solve the consumer’s problem the value function needs to be restated in a dynamic programming form.</p>
<div class="math notranslate nohighlight">
\[J(t, x; c, p, \theta) \triangleq E \left[\int_0^{T \wedge \tau} U(c(s),s)ds + B(Z(\tau),\tau)1_{\{\tau \ge T\}} + L(X(T))1_{\{\tau&gt;T\}}| \tau&gt; t, \mathcal{F}_t \right] \]</div>
<p>The value function becomes</p>
<div class="math notranslate nohighlight">
\[ V(t,x) \triangleq \sup_{\{c,p,\theta\} \in \mathcal{A}(t,x)} J(t, x; c, p, \theta)  \]</div>
<p>Because <span class="math notranslate nohighlight">\(\tau\)</span> is independent of the filtration, the value function can be rewritten as</p>
<div class="math notranslate nohighlight">
\[ E \left[\int_0^T  \bar{F}(s,t)U(c(s),s) + f(s,t)B(Z(\tau),\tau) ds  + \bar{F}(T,t)L(X(T))| \mathcal{F}_t \right]\]</div>
<p>The optimization problem is now converted from a random  closing time point to a fixed closing time point. The mortality rate can also be seen as a discounting function for the consumer as he would value the utility on the probability of survival.</p>
<p>Following the dynamic programming principle we can rewrite this equation as the value function at time s plus the value created from time step t to time step s. This enables us to view the optimization problem into a time step setting, giving us the incremental value gained at each point in time.</p>
<div class="math notranslate nohighlight">
\[ V(t,x) = \sup_{\{c,p,\theta\} \in \mathcal{A}(t,x)} E\left[e^{-\int_t^s\lambda(v)dv}V(s,X(s)) + \int_t^s f(s,t)B(Z(s),s) + \bar{F}(s,t)U(c(s),s)ds|\mathcal{F}_t\right] \]</div>
<p>The Hamiltonian-Jacobi-bellman (HJB) equation can be derived from the dynamic programming principle and is as follows</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{gather*}
\begin{cases} 
V_t(t,x) -\lambda V(t,x) + \sup_{(c,p,\theta)} \Psi(t,x;c,p,\theta)  = 0 \\ V(T,x) = L(x)  
\end{cases}
\end{gather*}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\begin{split} \Psi(t,x; c,p,\theta) \triangleq r(t)x + \theta(\mu(t) -r(t)) + i(t) -c -p)V_x(t,x) + \\ \frac{1}{2}\sigma^2(t)\theta^2V_{xx}(t,x) + \lambda(t)B(x+ p/\eta(t),t) + U(c,t) \end{split}\]</div>
<p>Proofs for deriving the HJB equation, dynammic programming principle and converting from a random closing time point to a fixed closing time point can be found in Ye <span id="id16">[<a class="reference internal" href="#id24">Ye06</a>]</span></p>
<p>A strategy is optimal if</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{gather*}
0 =V_t(t,x) -\lambda(t)V(t,x) + \sup_{c,p,\theta}(t,x;c,p,\theta)  \\
0 = V_t(t,x) -\lambda(t)V(t,x) + (r(t)x+ i(t))V_x + \sup_c\{U(c,t)-cV_x\} + \\ \sup_p\{\lambda(t)B(x + p/\eta(t),t) - pV_x\} + \sup_\theta \{ \frac{1}{2}\sigma^2(t)V_{xx}(t,x)\theta^2 +(\mu(t) - r(t))V_x(t,x)\theta\} 
\end{gather*}\]</div>
<p>The first order conditions for regular interior maximum are</p>
<div class="math notranslate nohighlight">
\[\sup_c  \{ U(c,t) - cV_x\} = \Psi_c(t,x;c^*,p^*,\theta^*)  \rightarrow  0 = -V_x(t,x) + U_c(c*,t) \]</div>
<div class="math notranslate nohighlight">
\[\begin{split} \sup_p\{\lambda(t)B(x + p/\eta(t),t) - pV_x\} = \Psi_p(t,x;c^*,p^*,\theta^*) \\ \rightarrow 0 = -V_x(t,x) + \frac{\lambda(t)}{\eta{t}}B_Z(x + p^*/\eta(t),t) \end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split} \sup_\theta \{ \frac{1}{2}\sigma^2(t)V_{xx}(t,x)\theta^2 +(\mu(t) - r(t))V_x(t,x)\theta\} = \Psi_\theta(t,x;c^*,p^*,\theta^*)\\ \rightarrow 0 = (\mu(t) -r(t))V_x(t,x) + \sigma^2(t)\theta^*V_{xx}(t,x) \end{split}\]</div>
<p>The second order conditions are</p>
<div class="math notranslate nohighlight">
\[ \Psi_{cc}, \Psi_{pp}, \Psi_{\theta \theta} &lt; 0 \]</div>
</div>
<div class="section" id="the-analytic-result-constant-relative-risk-aversion-utility-function">
<h3><span class="section-number">3.1.3. </span>The analytic result: Constant Relative Risk Aversion utility function<a class="headerlink" href="#the-analytic-result-constant-relative-risk-aversion-utility-function" title="Permalink to this headline">¶</a></h3>
<p>This optimal control problem has been solved analytically by Ye <span id="id17">[<a class="reference internal" href="#id24">Ye06</a>]</span> for the Constant Relative Risk Aversion utility function. In this paper however, I will use the analytical result derived by Ye to compare the performance of the NeuralNetDiffEq algorithm and see whether this convergences to the analytical result derived by Ye. Once this is established, other utility function might be used for solving the optimal control problem using the NeuralNetDiffEq algorithm.</p>
</div>
</div>
<div class="section" id="algorithm-bfsde">
<h2><span class="section-number">3.2. </span>Algorithm BFSDE<a class="headerlink" href="#algorithm-bfsde" title="Permalink to this headline">¶</a></h2>
<p id="id18"><dl class="citation">
<dt class="label" id="id51"><span class="brackets">ADBB17</span></dt>
<dd><p>Kai Arulkumaran, Marc Peter Deisenroth, Miles Brundage, and Anil Anthony Bharath. A brief survey of deep reinforcement learning. <em>arXiv preprint arXiv:1708.05866</em>, 2017.</p>
</dd>
<dt class="label" id="id26"><span class="brackets">BFH17</span></dt>
<dd><p>Qianwen Bi, Michael Finke, and Sandra J Huston. Financial software use and retirement savings. <em>Journal of Financial Counseling and Planning</em>, 28(1):107–128, 2017.</p>
</dd>
<dt class="label" id="id25"><span class="brackets">BDTS20</span></dt>
<dd><p>Rachel Qianwen Bi, Lukas R Dean, Jingpeng Tang, and Hyrum L Smith. Limitations of retirement planning software: examining variance between inputs and outputs. <em>Journal of Financial Service Professionals</em>, 2020.</p>
</dd>
<dt class="label" id="id30"><span class="brackets"><a class="fn-backref" href="#id8">BS11</a></span></dt>
<dd><p>Kenneth Bruhn and Mogens Steffensen. Household consumption, investment and life insurance. <em>Insurance: Mathematics and Economics</em>, 48(3):315–325, 2011.</p>
</dd>
<dt class="label" id="id36"><span class="brackets"><a class="fn-backref" href="#id13">CL20</a></span></dt>
<dd><p>Shou Chen and Guangbing Li. Time-inconsistent preferences, consumption, investment and life insurance decisions. <em>Applied Economics Letters</em>, 27(5):392–399, 2020.</p>
</dd>
<dt class="label" id="id37"><span class="brackets">DPMSNR14</span><span class="fn-backref">(<a href="#id12">1</a>,<a href="#id14">2</a>)</span></dt>
<dd><p>Albert De-Paz, Jesus Marin-Solano, Jorge Navas, and Oriol Roch. Consumption, investment and life insurance strategies with heterogeneous discounting. <em>Insurance: Mathematics and Economics</em>, 54:66–75, 2014.</p>
</dd>
<dt class="label" id="id27"><span class="brackets">DMBE18</span></dt>
<dd><p>Taft Dorman, Barry S Mulholland, Qianwen Bi, and Harold Evensky. The efficacy of publicly-available retirement planning tools. <em>Available at SSRN 2732927</em>, 2018.</p>
</dd>
<dt class="label" id="id54"><span class="brackets">EWC21</span></dt>
<dd><p>Maria K Eckstein, Linda Wilbrecht, and Anne GE Collins. What do reinforcement learning models measure? interpreting model parameters in cognition and neuroscience. <em>Current Opinion in Behavioral Sciences</em>, 41:128–137, 2021.</p>
</dd>
<dt class="label" id="id56"><span class="brackets">FranccoisLHI+18</span></dt>
<dd><p>Vincent François-Lavet, Peter Henderson, Riashat Islam, Marc G Bellemare, and Joelle Pineau. An introduction to deep reinforcement learning. <em>arXiv preprint arXiv:1811.12560</em>, 2018.</p>
</dd>
<dt class="label" id="id50"><span class="brackets">Ham18</span></dt>
<dd><p>Ahmad Hammoudeh. A concise introduction to reinforcement learning. 2018.</p>
</dd>
<dt class="label" id="id29"><span class="brackets">Her11</span></dt>
<dd><p>Hal E Hershfield. Future self-continuity: how conceptions of the future self transform intertemporal choice. <em>Annals of the New York Academy of Sciences</em>, 1235:30, 2011.</p>
</dd>
<dt class="label" id="id32"><span class="brackets"><a class="fn-backref" href="#id10">KS15</a></span></dt>
<dd><p>Morten Tolver Kronborg and Mogens Steffensen. Optimal consumption, investment and life insurance with surrender option guarantee. <em>Scandinavian Actuarial Journal</em>, 2015(1):59–87, 2015.</p>
</dd>
<dt class="label" id="id23"><span class="brackets"><a class="fn-backref" href="#id2">Leu94</a></span></dt>
<dd><p>Siu Fai Leung. Uncertain lifetime, the theory of the consumer, and the life cycle hypothesis. 1994.</p>
</dd>
<dt class="label" id="id49"><span class="brackets">Lev18</span></dt>
<dd><p>Sergey Levine. Reinforcement learning and control as probabilistic inference: tutorial and review. <em>arXiv preprint arXiv:1805.00909</em>, 2018.</p>
</dd>
<dt class="label" id="id20"><span class="brackets"><a class="fn-backref" href="#id4">Mer69</a></span></dt>
<dd><p>Robert C Merton. Lifetime portfolio selection under uncertainty: the continuous-time case. <em>The review of Economics and Statistics</em>, pages 247–257, 1969.</p>
</dd>
<dt class="label" id="id21"><span class="brackets"><a class="fn-backref" href="#id4">Mer75</a></span></dt>
<dd><p>Robert C Merton. Optimum consumption and portfolio rules in a continuous-time model. In <em>Stochastic Optimization Models in Finance</em>, pages 621–661. Elsevier, 1975.</p>
</dd>
<dt class="label" id="id28"><span class="brackets">PVW11</span></dt>
<dd><p>James M Poterba, Steven F Venti, and David A Wise. Were they prepared for retirement? financial status at advanced ages in the hrs and ahead cohorts. In <em>Investigations in the Economics of Aging</em>, pages 21–69. University of Chicago Press, 2011.</p>
</dd>
<dt class="label" id="id22"><span class="brackets"><a class="fn-backref" href="#id3">Ric75</a></span></dt>
<dd><p>Scott F Richard. Optimal consumption, portfolio and life insurance rules for an uncertain lived individual in a continuous time model. <em>Journal of Financial Economics</em>, 2(2):187–203, 1975.</p>
</dd>
<dt class="label" id="id34"><span class="brackets"><a class="fn-backref" href="#id11">SW16</a></span></dt>
<dd><p>Yang Shen and Jiaqin Wei. Optimal investment-consumption-insurance with random parameters. <em>Scandinavian Actuarial Journal</em>, 2016(1):37–62, 2016.</p>
</dd>
<dt class="label" id="id55"><span class="brackets">SB18</span></dt>
<dd><p>Richard S Sutton and Andrew G Barto. <em>Reinforcement learning: An introduction</em>. MIT press, 2018.</p>
</dd>
<dt class="label" id="id33"><span class="brackets"><a class="fn-backref" href="#id9">WCJW20</a></span></dt>
<dd><p>Jiaqin Wei, Xiang Cheng, Zhuo Jin, and Hao Wang. Optimal consumption–investment and life-insurance purchase strategy for couples with correlated lifetimes. <em>Insurance: Mathematics and Economics</em>, 91:244–256, 2020.</p>
</dd>
<dt class="label" id="id19"><span class="brackets"><a class="fn-backref" href="#id1">Yaa65</a></span></dt>
<dd><p>Menahem E Yaari. Uncertain lifetime, life insurance, and the theory of the consumer. <em>The Review of Economic Studies</em>, 32(2):137–150, 1965.</p>
</dd>
<dt class="label" id="id24"><span class="brackets">Ye06</span><span class="fn-backref">(<a href="#id5">1</a>,<a href="#id6">2</a>,<a href="#id7">3</a>,<a href="#id15">4</a>,<a href="#id16">5</a>,<a href="#id17">6</a>)</span></dt>
<dd><p>Jinchun Ye. <em>Optimal life insurance purchase, consumption and portfolio under an uncertain life</em>. University of Illinois at Chicago, 2006.</p>
</dd>
</dl>
</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "julia-1.6"
        },
        kernelOptions: {
            kernelName: "julia-1.6",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'julia-1.6'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="Reinforcement_learning.html" title="previous page"><span class="section-number">2. </span>Reinforcement Learning</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Ignace Decocq<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>